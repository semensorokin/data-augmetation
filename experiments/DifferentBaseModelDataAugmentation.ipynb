{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DifferentBaseModelDataAugmentation.ipynb","provenance":[],"authorship_tag":"ABX9TyN6Jxegu+ydLhWu9VAy8E7Z"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"LTwc9QRfG6L0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"1dfcbe94-6a56-4799-cdd9-6f32a5e33525","executionInfo":{"status":"ok","timestamp":1585991779167,"user_tz":-180,"elapsed":658,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/'My Drive'/UniversalEmb"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/UniversalEmb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xptVzP80e-b2","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from sklearn import model_selection\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import f1_score\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","\n","\n","def train_model(n_examples=5000, n_classes=1, model = LogisticRegression,  augm_texts=None, augme_labels=None):\n","  labels = [i.split(' ', 1)[0].split(':')[n_classes] for i in open('train_5500.label', encoding = 'windows-1252').readlines()][:n_examples]\n","  texts = [ i.split(' ', 1)[1][:-1] for i in open('train_5500.label', encoding = 'windows-1252').readlines()][:n_examples]\n","  if augm_texts is not None:\n","    train  = pd.DataFrame({'texts':texts + augm_texts, 'labels': labels + augme_labels})\n","  else:\n","    print('Training process on clear data with {0} samples on trec {1} with model {2}'.format(n_examples, n_classes, str(model)))\n","    train  = pd.DataFrame({'texts':texts , 'labels': labels})\n","\n","  labels_t = [i.split(' ', 1)[0].split(':')[n_classes] for i in open('TREC_10.label', encoding = 'windows-1252').readlines()]\n","  texts_t = [ i.split(' ', 1)[1][:-1] for i in open('TREC_10.label', encoding = 'windows-1252').readlines()]\n","  test  = pd.DataFrame({'texts':texts_t, 'labels': labels_t})\n","  tfidf_vectorizer = TfidfVectorizer(lowercase = False, ngram_range = (1,3), max_df =0.98, min_df = 3)\n","  tfidf_lr_pipe = Pipeline([('tfidf', tfidf_vectorizer), ('lr', model())])\n","  tfidf_lr_pipe.fit(train.texts.values, train.labels.values)\n","  predicted_labels = tfidf_lr_pipe.predict(test.texts.values)\n","  f1 = f1_score(labels_t, predicted_labels, average='micro')\n","  print('F1 test - {:.4f}'.format(f1))\n","  return f1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xRhWD1miLT7w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"537b08be-0c25-436d-adc1-faf4ab26d8e8","executionInfo":{"status":"ok","timestamp":1585992130363,"user_tz":-180,"elapsed":183050,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}}},"source":["results = []\n","for dataset in [0,1]:\n","  print(\"NEW DATASET\")\n","  datasettype = []\n","  for model in [RandomForestClassifier, AdaBoostClassifier, MLPClassifier, MultinomialNB, DecisionTreeClassifier, SVC, LogisticRegression]:\n","    print(\"NEW MODEL\")\n","    models = []\n","    for n_examples in [5000, 4000, 3000, 2000, 1000, 500, 400, 300]:\n","      models.append(train_model(n_examples, dataset, model))\n","    datasettype.append(models)\n","  results.append(datasettype)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["NEW DATASET\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.8440\n","Training process on clear data with 4000 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.8260\n","Training process on clear data with 3000 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.8320\n","Training process on clear data with 2000 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.8040\n","Training process on clear data with 1000 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.7460\n","Training process on clear data with 500 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.7020\n","Training process on clear data with 400 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.6960\n","Training process on clear data with 300 samples on trec 0 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.6280\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.5960\n","Training process on clear data with 4000 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.5540\n","Training process on clear data with 3000 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.6100\n","Training process on clear data with 2000 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.4360\n","Training process on clear data with 1000 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.4560\n","Training process on clear data with 500 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.4220\n","Training process on clear data with 400 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.4280\n","Training process on clear data with 300 samples on trec 0 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.3800\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n","F1 test - 0.8700\n","Training process on clear data with 4000 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n","F1 test - 0.8500\n","Training process on clear data with 3000 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n","F1 test - 0.8320\n","Training process on clear data with 2000 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.8080\n","Training process on clear data with 1000 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.7940\n","Training process on clear data with 500 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.6940\n","Training process on clear data with 400 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.6540\n","Training process on clear data with 300 samples on trec 0 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.6480\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.8120\n","Training process on clear data with 4000 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.8000\n","Training process on clear data with 3000 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.7820\n","Training process on clear data with 2000 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.7560\n","Training process on clear data with 1000 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.7020\n","Training process on clear data with 500 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.6420\n","Training process on clear data with 400 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.5900\n","Training process on clear data with 300 samples on trec 0 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.5960\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.8000\n","Training process on clear data with 4000 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.8020\n","Training process on clear data with 3000 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.7700\n","Training process on clear data with 2000 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.8020\n","Training process on clear data with 1000 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.7020\n","Training process on clear data with 500 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.6780\n","Training process on clear data with 400 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.6620\n","Training process on clear data with 300 samples on trec 0 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.6380\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.8580\n","Training process on clear data with 4000 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.8520\n","Training process on clear data with 3000 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.8400\n","Training process on clear data with 2000 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.8040\n","Training process on clear data with 1000 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.7560\n","Training process on clear data with 500 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.6920\n","Training process on clear data with 400 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.6600\n","Training process on clear data with 300 samples on trec 0 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.6220\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.8740\n","Training process on clear data with 4000 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.8560\n","Training process on clear data with 3000 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.8400\n","Training process on clear data with 2000 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.8080\n","Training process on clear data with 1000 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.7520\n","Training process on clear data with 500 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.6780\n","Training process on clear data with 400 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.6500\n","Training process on clear data with 300 samples on trec 0 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.6300\n","NEW DATASET\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.7620\n","Training process on clear data with 4000 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.7540\n","Training process on clear data with 3000 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.7440\n","Training process on clear data with 2000 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.7200\n","Training process on clear data with 1000 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.6300\n","Training process on clear data with 500 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.6060\n","Training process on clear data with 400 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.5880\n","Training process on clear data with 300 samples on trec 1 with model <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","F1 test - 0.5580\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2680\n","Training process on clear data with 4000 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2420\n","Training process on clear data with 3000 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2360\n","Training process on clear data with 2000 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2360\n","Training process on clear data with 1000 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2360\n","Training process on clear data with 500 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2360\n","Training process on clear data with 400 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2320\n","Training process on clear data with 300 samples on trec 1 with model <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n","F1 test - 0.2520\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.7880\n","Training process on clear data with 4000 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.7720\n","Training process on clear data with 3000 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.7640\n","Training process on clear data with 2000 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.7180\n","Training process on clear data with 1000 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.6800\n","Training process on clear data with 500 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.6160\n","Training process on clear data with 400 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.5620\n","Training process on clear data with 300 samples on trec 1 with model <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.5500\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.6340\n","Training process on clear data with 4000 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.6220\n","Training process on clear data with 3000 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.6040\n","Training process on clear data with 2000 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.5860\n","Training process on clear data with 1000 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.5680\n","Training process on clear data with 500 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.5400\n","Training process on clear data with 400 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.5120\n","Training process on clear data with 300 samples on trec 1 with model <class 'sklearn.naive_bayes.MultinomialNB'>\n","F1 test - 0.4880\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.7100\n","Training process on clear data with 4000 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.7220\n","Training process on clear data with 3000 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.7100\n","Training process on clear data with 2000 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.6940\n","Training process on clear data with 1000 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.6140\n","Training process on clear data with 500 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.6060\n","Training process on clear data with 400 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.5700\n","Training process on clear data with 300 samples on trec 1 with model <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","F1 test - 0.5620\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.7480\n","Training process on clear data with 4000 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.7300\n","Training process on clear data with 3000 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.7160\n","Training process on clear data with 2000 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.6800\n","Training process on clear data with 1000 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.6200\n","Training process on clear data with 500 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.5700\n","Training process on clear data with 400 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.5480\n","Training process on clear data with 300 samples on trec 1 with model <class 'sklearn.svm._classes.SVC'>\n","F1 test - 0.5300\n","NEW MODEL\n","Training process on clear data with 5000 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["F1 test - 0.7160\n","Training process on clear data with 4000 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.7060\n","Training process on clear data with 3000 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.7060\n","Training process on clear data with 2000 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.6580\n","Training process on clear data with 1000 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.6160\n","Training process on clear data with 500 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.5720\n","Training process on clear data with 400 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.5580\n","Training process on clear data with 300 samples on trec 1 with model <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","F1 test - 0.5360\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HTX7xnJTOUu8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"79301f3d-ec12-4800-9bfb-8058ef274954","executionInfo":{"status":"ok","timestamp":1585990313971,"user_tz":-180,"elapsed":749,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}}},"source":["results"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[[0.824, 0.818, 0.806, 0.768, 0.676, 0.588],\n","  [0.818, 0.802, 0.79, 0.762, 0.718, 0.612],\n","  [0.676, 0.654, 0.604, 0.59, 0.548, 0.54],\n","  [0.808, 0.802, 0.786, 0.764, 0.69, 0.586]],\n"," [[0.498, 0.518, 0.506, 0.532, 0.498, 0.462],\n","  [0.65, 0.632, 0.632, 0.596, 0.552, 0.538],\n","  [0.596, 0.57, 0.546, 0.532, 0.512, 0.436],\n","  [0.682, 0.67, 0.65, 0.598, 0.54, 0.474]]]"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"f2_-8G7GTfMi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"outputId":"a591624f-daa5-4805-b887-64fe78596642","executionInfo":{"status":"ok","timestamp":1585992152823,"user_tz":-180,"elapsed":545,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}}},"source":["results"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[[0.844, 0.826, 0.832, 0.804, 0.746, 0.702, 0.696, 0.628],\n","  [0.596, 0.554, 0.61, 0.436, 0.456, 0.422, 0.428, 0.38],\n","  [0.87, 0.85, 0.832, 0.808, 0.7940000000000002, 0.694, 0.654, 0.648],\n","  [0.8119999999999999,\n","   0.8000000000000002,\n","   0.782,\n","   0.756,\n","   0.702,\n","   0.642,\n","   0.59,\n","   0.596],\n","  [0.8000000000000002,\n","   0.802,\n","   0.7699999999999999,\n","   0.802,\n","   0.702,\n","   0.678,\n","   0.662,\n","   0.638],\n","  [0.858, 0.852, 0.8399999999999999, 0.804, 0.756, 0.692, 0.66, 0.622],\n","  [0.874, 0.856, 0.8399999999999999, 0.808, 0.752, 0.678, 0.65, 0.63]],\n"," [[0.762, 0.754, 0.744, 0.72, 0.63, 0.606, 0.588, 0.558],\n","  [0.268, 0.242, 0.236, 0.236, 0.236, 0.236, 0.232, 0.252],\n","  [0.788, 0.772, 0.764, 0.718, 0.68, 0.616, 0.562, 0.55],\n","  [0.634, 0.622, 0.604, 0.586, 0.568, 0.54, 0.512, 0.488],\n","  [0.7100000000000001,\n","   0.722,\n","   0.7100000000000001,\n","   0.694,\n","   0.614,\n","   0.606,\n","   0.57,\n","   0.562],\n","  [0.748,\n","   0.7299999999999999,\n","   0.7160000000000001,\n","   0.68,\n","   0.62,\n","   0.57,\n","   0.548,\n","   0.53],\n","  [0.7160000000000001, 0.706, 0.706, 0.658, 0.616, 0.572, 0.558, 0.536]]]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"1eIUq75Qf7Rv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}