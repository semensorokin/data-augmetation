{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AugmenUseEnsambleModels.ipynb","provenance":[],"authorship_tag":"ABX9TyOkCTK+HjdtKen5y6Yw6HmJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"D56NWaBa9IpE","colab_type":"code","outputId":"895424fb-94e6-4b3e-900e-af2a0e9df8d1","executionInfo":{"status":"ok","timestamp":1590313319586,"user_tz":-180,"elapsed":22039,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":629}},"source":["!apt install libomp-dev\n","!python -m pip install --upgrade faiss faiss-gpu"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libomp5\n","Suggested packages:\n","  libomp-doc\n","The following NEW packages will be installed:\n","  libomp-dev libomp5\n","0 upgraded, 2 newly installed, 0 to remove and 31 not upgraded.\n","Need to get 239 kB of archives.\n","After this operation, 804 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n","Fetched 239 kB in 1s (295 kB/s)\n","Selecting previously unselected package libomp5:amd64.\n","(Reading database ... 144433 files and directories currently installed.)\n","Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n","Unpacking libomp5:amd64 (5.0.1-1) ...\n","Selecting previously unselected package libomp-dev.\n","Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n","Unpacking libomp-dev (5.0.1-1) ...\n","Setting up libomp5:amd64 (5.0.1-1) ...\n","Setting up libomp-dev (5.0.1-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Collecting faiss\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/1c/4ae6cb87cf0c09c25561ea48db11e25713b25c580909902a92c090b377c0/faiss-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.7MB)\n","\u001b[K     |████████████████████████████████| 4.7MB 3.4MB/s \n","\u001b[?25hCollecting faiss-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/69/0e3f56024bb1423a518287673071ae512f9965d1faa6150deef5cc9e7996/faiss_gpu-1.6.3-cp36-cp36m-manylinux2010_x86_64.whl (35.5MB)\n","\u001b[K     |████████████████████████████████| 35.5MB 91kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from faiss) (1.18.4)\n","Installing collected packages: faiss, faiss-gpu\n","Successfully installed faiss-1.5.3 faiss-gpu-1.6.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JJZH9GINWv5h","colab_type":"code","outputId":"4367dda9-3cbf-48ea-bcec-92df1c4e82da","executionInfo":{"status":"ok","timestamp":1590313326849,"user_tz":-180,"elapsed":29293,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":561}},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n","\u001b[K     |████████████████████████████████| 665kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 17.1MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 15.5MB/s \n","\u001b[?25hCollecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 34.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=7f390abb1e2dfe03c47213acc1827a64d5351e99979805e50e3ca076f65f6bff\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bpT7uLQqDiic","colab_type":"code","colab":{}},"source":["import faiss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fib3JWGEytzb","colab_type":"code","outputId":"ec7fe607-c201-451e-edf5-8602f16458fd","executionInfo":{"status":"ok","timestamp":1590313351219,"user_tz":-180,"elapsed":53655,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/'My Drive'/UniversalEmb"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/UniversalEmb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G-P0DhBZmRJv","colab_type":"code","outputId":"b08246c3-4698-4fca-9a04-362c7db149c9","executionInfo":{"status":"ok","timestamp":1590313353969,"user_tz":-180,"elapsed":569,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd Question_augmentation "],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/UniversalEmb/Question_augmentation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Es0qV0f2li7R","colab_type":"code","outputId":"6e1c73d4-d277-4121-bfd3-0b1fd52e7987","executionInfo":{"status":"ok","timestamp":1590313364199,"user_tz":-180,"elapsed":1988,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!ls ../"],"execution_count":6,"outputs":[{"output_type":"stream","text":[" augm_emb.npy\n"," bert_2500_squad_055.csv\n"," BoolQ_Dataset_dev.jsonl\n"," BoolQ_Dataset_train.jsonl\n"," bpe_emv.vec\n"," bpe_emv.vec.pt\n"," crawl-300d-2M.vec\n"," crawl-300d-2M.vec.zip\n"," dev.jsonl\n"," dev.txt\n"," eda_nlp\n","'open?id=0BwmD_VLjROrfTTljRDVZMFJnVWM'\n"," Question_augmentation\n"," SQuAD_emb.npy\n"," SST\n"," sst2-splited\n"," stsa.binary.train\n"," test.csv\n"," test.tsv\n"," test.txt\n"," train_5500.label\n"," train_bert_emb3k.npy\n"," train_bert_emb4k.npy\n"," train_bert_emb.npy\n"," train.csv\n"," train_emb.npy\n"," train.jsonl\n"," train.tsv\n"," train.txt\n"," train-v2.0.json\n"," TREC_10.label\n"," trec-50_clear_3000_samples.txt\n"," trec-50_clear_4000_samples.txt\n"," trec-50_clear_5000_samples.txt\n"," TREC50_Dataset_random_with_same_n_classes_Model_number_3_Bert_#0_squad_0.7.csv\n"," TREC50_Dataset_random_with_same_n_classes_Model_number_3_Bert_#1_squad_0.7.csv\n"," TREC50_Dataset_random_with_same_n_classes_Model_number_3_Bert_#2_squad_0.7.csv\n"," trec-50_eda_aug_3000_samples.txt\n"," trec-50_eda_aug_4000_samples.txt\n"," trec-50_eda_aug_5000_samples.txt\n"," trec50_n1_bert_0_boolq_075_with_min_max_distance.csv\n"," trec50_n1_bert_0_wiki_075_with_min_max_distance.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-mean_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-mean_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-mean_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-mean_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-mean_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-mean_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-mean_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.3_min_b-min_max_b-mean_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-mean_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-mean_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-mean_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-mean_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-mean_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-mean_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-mean_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.5_min_b-min_max_b-mean_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-mean_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-mean_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-mean_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-mean_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-mean_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-mean_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-mean_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.75_min_b-min_max_b-mean_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-mean_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-mean_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-mean_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-mean_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-max_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-max_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-max_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-max_coefs2-2.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-mean_coefs0.5-0.5.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-mean_coefs0.5-2.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-mean_coefs1-1.csv\n"," trec50_n1_bert_squad_pr_b-0.9_min_b-min_max_b-mean_coefs2-2.csv\n"," trec50_n3_bert_0_squad_05_with_mean_max_distance.csv\n"," trec50_n3_bert_0_squad_065.csv\n"," trec50_n3_bert_0_squad_07_with_mean_max_distance.csv\n"," trec50_n3_bert_1_squad_065.csv\n"," trec50_n3_bert_2_squad_065.csv\n"," trec50_splited\n"," trec6_splited\n"," trees\n"," wikitext-103\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tAPboq84dKSQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"d7b7f466-66e0-41aa-b995-44d8d3b762af","executionInfo":{"status":"ok","timestamp":1590313373959,"user_tz":-180,"elapsed":5774,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}}},"source":["import torch\n","torch.manual_seed(0)\n","import numpy as np\n","np.random.seed(0)\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","import os\n","import pandas as pd\n","import re\n","import seaborn as sns\n","import transformers\n","from transformers import AdamW\n","from torch import nn\n","from transformers import get_linear_schedule_with_warmup\n","import time\n","import datetime\n","import random\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from tqdm import tqdm"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eZn1gtuHaV1M","colab_type":"code","colab":{}},"source":["def read_trec50(file_name, typ=1):\n","  train = pd.read_csv(file_name, index_col=0)\n","  lbl2indx = {i:j for j, i in enumerate(train.labels.unique())}\n","  train.columns = ['text', 'labels']\n","  train['lbl_index'] = train.labels.apply(lambda x:lbl2indx[x])\n","  labels_t = [i.split(' ', 1)[0].split(':')[typ] for i in open('../TREC_10.label', encoding = 'windows-1252').readlines()]\n","  texts_t = [ i.split(' ', 1)[1][:-1] for i in open('../TREC_10.label', encoding = 'windows-1252').readlines()]\n","  test  = pd.DataFrame({'text':texts_t, 'labels': labels_t})\n","  test['lbl_index'] = test.labels.apply(lambda x:lbl2indx[x])\n","\n","  return train, test, lbl2indx\n","\n","train, test, l2i = read_trec50('../trec50_splited/trec50_5k.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bmmK2DCmExU","colab_type":"code","colab":{}},"source":["import pandas as pd\n","def read_trec6(file_name, typ=0):\n","  train = pd.read_csv(file_name, index_col=0)\n","  lbl2indx = {i:j for j, i in enumerate(train.labels.unique())}\n","  train.columns = ['text', 'labels']\n","  train['lbl_index'] = train.labels.apply(lambda x:lbl2indx[x])\n","\n","\n","  labels_t = [i.split(' ', 1)[0].split(':')[typ] for i in open('../TREC_10.label', encoding = 'windows-1252').readlines()]\n","  texts_t = [ i.split(' ', 1)[1][:-1] for i in open('../TREC_10.label', encoding = 'windows-1252').readlines()]\n","  test  = pd.DataFrame({'text':texts_t, 'labels': labels_t})\n","  test['lbl_index'] = test.labels.apply(lambda x:lbl2indx[x])\n","\n","  return train, test, lbl2indx\n","train, test, l2i = read_trec6('../trec6_splited/trec6_splited_4k.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRPfmuIFZwKm","colab_type":"code","outputId":"487c83c6-5e5b-4da2-e8bf-100e1e8ed8a8","executionInfo":{"status":"ok","timestamp":1590003997275,"user_tz":-180,"elapsed":3417,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!ls ../trec6_splited"],"execution_count":0,"outputs":[{"output_type":"stream","text":["augmented_with_eda  trec6_splited_3k.csv  trec6_splited_5k.csv\n","prepared_for_eda    trec6_splited_4k.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mYPlLfodPmV6","colab_type":"text"},"source":["искать примеры только к тренировочным примерам которые являются цетром категории "]},{"cell_type":"code","metadata":{"id":"6Vi5QitYMmwI","colab_type":"code","colab":{}},"source":["MAX_SEQ_LEN = 64\n","BATCH_SIZE = 128\n","pretrained_weights = 'bert-base-cased'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOJxtkHnR1gv","colab_type":"text"},"source":["## Train 4 BertLSTM"]},{"cell_type":"code","metadata":{"id":"2bBdb3pt8LuQ","colab_type":"code","colab":{}},"source":["\n","def prep_data(sentences, tokenizer, MAX_LEN = MAX_SEQ_LEN):\n","  filtred_by_len =[]\n","  input_ids = []\n","  s=0\n","  for sent in sentences:\n","      encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n","      if len(encoded_sent) <= MAX_LEN:\n","        input_ids.append(encoded_sent)\n","        filtred_by_len.append(sent)\n","      else:\n","        s+=1\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","  attention_masks = []\n","  for sent in input_ids:\n","      att_mask = [int(token_id > 0) for token_id in sent]\n","      attention_masks.append(att_mask)\n","  print(\"Not used sentence because it bpe len > {} : {}\".format(MAX_LEN, s))\n","  return input_ids, attention_masks, filtred_by_len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvSv_6GIcaLm","colab_type":"code","colab":{}},"source":["class BertEmbeddingLayer(torch.nn.Module):\n","\n","    def __init__(self, embedding_layer, padding_idx=0):\n","        super().__init__()\n","\n","        self.embedding_layer = embedding_layer\n","        self.padding_idx = padding_idx\n","\n","    def forward(self, x):\n","\n","        embed = self.embedding_layer(x)\n","\n","        pad_mask = x != self.padding_idx\n","        pad_mask = pad_mask.unsqueeze(-1).repeat(1, 1, embed.size(-1)).float()\n","\n","        embed = embed * pad_mask\n","\n","        return embed"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFsCTp_mporB","colab_type":"code","colab":{}},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","  \n","def format_time(elapsed):\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","import keras.backend as K\n","def f1(y_true, y_pred): #taken from old keras source code\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n","    return f1_val\n","\n","class BertEmbdLSTMPooling(torch.nn.Module):\n","  def __init__(self, n_class, b_e):\n","    super(BertEmbdLSTMPooling, self).__init__()\n","    self.embed = BertEmbeddingLayer(embedding_layer=b_e , padding_idx=0)\n","    self.lstm = nn.LSTM(768, 256, num_layers=1,  bidirectional=True, dropout=0.35,batch_first = True)\n","    self.linear = nn.Linear(512, n_class)\n","\n","  def forward(self, x):\n","    x = self.embed(x)\n","    #print(x.shape)\n","    x, _ = self.lstm(x)\n","    #print(x.shape)\n","\n","    value, indx = torch.max(x, dim = 1)\n","    #print(value.shape)\n","    return self.linear(value)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lJBQY6Ye-73","colab_type":"code","colab":{}},"source":["def train_BertEmbdLSTMPooling(train, test):  \n","  tokenizer_ = transformers.BertTokenizer.from_pretrained(pretrained_weights)\n","  bert_emb_ = transformers.BertModel.from_pretrained(pretrained_weights).embeddings\n","\n","  train_input_ids, train_attention_masks, filtred_train = prep_data(train.text.values.tolist(), tokenizer_)\n","  test_input_ids, test_attention_masks,filtred_test = prep_data(test.text.values.tolist(), tokenizer_)\n","  train_inputs = torch.tensor(train_input_ids)\n","  validation_inputs = torch.tensor(test_input_ids)\n","\n","  train_labels = torch.tensor(train.lbl_index.values.tolist())\n","  validation_labels = torch.tensor(test.lbl_index.values.tolist())\n","\n","  train_masks = torch.tensor(train_attention_masks)\n","  validation_masks = torch.tensor(test_attention_masks)\n","\n","  batch_size = BATCH_SIZE\n","\n","  # Create the DataLoader for our training set.\n","  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","  print(\"Training example : {}\".format(len(train_data)))\n","  train_sampler = RandomSampler(train_data)\n","  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","  # Create the DataLoader for our validation set.\n","  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","  print(\"Valid example : {}\".format(len(validation_data)))\n","  validation_sampler = SequentialSampler(validation_data)\n","  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","  model = BertEmbdLSTMPooling(len(train.lbl_index.unique()), bert_emb_)\n","\n","  # Tell pytorch to run this model on the GPU.\n","  device = 'cuda'\n","  model = model.cuda()\n","\n","  epochs = 7\n","  total_steps = len(train_dataloader) * epochs\n","\n","  lf = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=0, reduce=None, reduction='mean')\n","  optimizer = AdamW(model.parameters(), lr = 0.001, eps=1e-07)\n","  scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                              num_warmup_steps = 10, # Default value in run_glue.py\n","                                              num_training_steps = total_steps)\n","\n","  loss_values = []\n","  best_model = None\n","  best_f1 = 0\n","\n","  for epoch_i in range(0, epochs):\n","      embeddings = []\n","      best_metrics = {'acc':[], 'f':[]}\n","\n","      print(\"\")\n","      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","      print('Training...')\n","      t0 = time.time()\n","      total_loss = 0\n","      model.train()\n","\n","      for step, batch in enumerate(train_dataloader):\n","          if step % 100 == 0 and not step == 0:\n","              elapsed = format_time(time.time() - t0)\n","              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","          b_input_ids = batch[0].to(device)\n","          \n","          b_labels = batch[2].to(device)\n","          model.zero_grad()        \n","\n","          outputs = model(b_input_ids)\n","          loss = lf(outputs, b_labels)\n","          total_loss += loss.item()\n","          loss.backward()\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","          optimizer.step()\n","          scheduler.step()\n","\n","      avg_train_loss = total_loss / len(train_dataloader)            \n","      loss_values.append(avg_train_loss)\n","\n","      print(\"\")\n","      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","      print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","          \n","      print(\"\")\n","      print(\"Running Validation...\")\n","\n","      t0 = time.time()\n","      test_targets, test_pred_class = [], []\n","\n","      model.eval()\n","\n","      eval_loss, eval_accuracy = 0, 0\n","      nb_eval_steps, nb_eval_examples = 0, 0\n","\n","      for batch in validation_dataloader:\n","          \n","          batch = tuple(t.to(device) for t in batch)\n","          \n","          b_input_ids, b_input_mask, b_labels = batch\n","          with torch.no_grad():        \n","              logits = model(b_input_ids)\n","\n","          # Move logits and labels to CPU\n","          logits = logits.detach().cpu().numpy()\n","          label_ids = b_labels.to('cpu').numpy()\n","          test_targets.append(label_ids)\n","          test_pred_class.append(np.argmax(logits, axis=1))\n","          \n","          # Calculate the accuracy for this batch of test sentences.\n","          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","          \n","          # Accumulate the total accuracy.\n","          eval_accuracy += tmp_eval_accuracy\n","\n","          nb_eval_steps += 1\n","      test_targets = np.concatenate(test_targets).squeeze()\n","      test_pred_class = np.concatenate(test_pred_class).squeeze()\n","\n","      acc = accuracy_score(test_targets, test_pred_class)\n","      f1 = f1_score(test_targets, test_pred_class, average='weighted')\n","\n","      if f1 > best_f1:\n","        best_f1 = f1\n","        best_model = model\n","\n","      best_metrics['acc'].append(acc)\n","\n","      # Report the final accuracy for this validation run.\n","      print(\"  Accuracy: {0:.5f}\".format(acc))\n","      print(\"  F1: {0:.5f}\".format(f1))\n","      print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","  print(\"\")\n","  print(\"Training complete!\")\n","  print( \"Accuracy: {}, F1:{}\".format(max(best_metrics['acc']), best_f1))\n","  return max(best_metrics['acc']), best_f1, model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkyYQHaI9pSJ","colab_type":"code","outputId":"1815d88a-c0f7-4cd7-a1f1-d8ec687bc2d5","executionInfo":{"status":"ok","timestamp":1590004073711,"user_tz":-180,"elapsed":79824,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["f1_scores, acc_scores, models = [], [], []\n","for _ in range(3):\n","  acccur, f1_sc, model = train_BertEmbdLSTMPooling(train, test)\n","  f1_scores.append(f1_sc)\n","  acc_scores.append(acccur)\n","  models.append(model)\n","  print('\\n\\n')\n","print(\"f1_average: {}, std:{}\".format(np.mean(f1_scores), np.std(f1_scores)))\n","print(\"acc_average: {}, std:{}\".format(np.mean(acc_scores), np.std(acc_scores)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 4004\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","  Average training loss: 1.11\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.57400\n","  F1: 0.52378\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.27\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.65600\n","  F1: 0.58816\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67400\n","  F1: 0.59689\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66800\n","  F1: 0.59173\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67400\n","  F1: 0.59369\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58609\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66800\n","  F1: 0.58804\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.668, F1:0.5968922018368837\n","\n","\n","\n","Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 4004\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n","\n","  Average training loss: 1.08\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.60200\n","  F1: 0.54189\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.25\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.65600\n","  F1: 0.57959\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.57881\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67400\n","  F1: 0.59431\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58650\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66200\n","  F1: 0.58345\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.58118\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.66, F1:0.594307797362162\n","\n","\n","\n","Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 4004\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n","\n","  Average training loss: 1.09\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.59400\n","  F1: 0.53238\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.65800\n","  F1: 0.58075\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67000\n","  F1: 0.58986\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67000\n","  F1: 0.59124\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58963\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66800\n","  F1: 0.59055\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67200\n","  F1: 0.59448\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.672, F1:0.5944809093415796\n","\n","\n","\n","f1_average: 0.5952269695135418, std:0.0011796160271833154\n","acc_average: 0.6666666666666666, std:0.004988876515698593\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vLqWda0raUxU","colab_type":"code","outputId":"4445e417-a815-4df0-b207-3a1155744c9f","executionInfo":{"status":"ok","timestamp":1590004073712,"user_tz":-180,"elapsed":79818,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["test"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","      <th>lbl_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How far is it from Denver to Aspen ?</td>\n","      <td>NUM</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What county is Modesto , California in ?</td>\n","      <td>LOC</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Who was Galileo ?</td>\n","      <td>HUM</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What is an atom ?</td>\n","      <td>DESC</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>When did Hawaii become a state ?</td>\n","      <td>NUM</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>Who was the 22nd President of the US ?</td>\n","      <td>HUM</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>What is the money they use in Zambia ?</td>\n","      <td>ENTY</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>How many feet in a mile ?</td>\n","      <td>NUM</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>What is the birthstone of October ?</td>\n","      <td>ENTY</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>What is e-coli ?</td>\n","      <td>DESC</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 3 columns</p>\n","</div>"],"text/plain":["                                         text labels  lbl_index\n","0        How far is it from Denver to Aspen ?    NUM          4\n","1    What county is Modesto , California in ?    LOC          5\n","2                           Who was Galileo ?    HUM          3\n","3                           What is an atom ?   DESC          0\n","4            When did Hawaii become a state ?    NUM          4\n","..                                        ...    ...        ...\n","495    Who was the 22nd President of the US ?    HUM          3\n","496    What is the money they use in Zambia ?   ENTY          1\n","497                 How many feet in a mile ?    NUM          4\n","498       What is the birthstone of October ?   ENTY          1\n","499                          What is e-coli ?   DESC          0\n","\n","[500 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"tcV2v6G5SAC1","colab_type":"code","outputId":"1de4ab81-8401-416a-fddb-a73c927f7aea","executionInfo":{"status":"ok","timestamp":1590004073712,"user_tz":-180,"elapsed":79812,"user":{"displayName":"Семен Сорокин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOIUUWk_YzzzBBifN_cm14_KVcOtDV3Fuy_9lY=s64","userId":"15238420249980587427"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["models[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertEmbdLSTMPooling(\n","  (embed): BertEmbeddingLayer(\n","    (embedding_layer): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (lstm): LSTM(768, 256, batch_first=True, dropout=0.35, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=6, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"ZTEUU6rWCSme","colab_type":"code","colab":{}},"source":["def USE_Embeder(input):\n","  module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n","  model = hub.load(module_url)\n","  return model(input)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hedZhgd7M8Xo","colab_type":"code","colab":{}},"source":["def get_k_near_neibs(train_vectors, augmented_vectors, k=5):  \n","  res = faiss.StandardGpuResources()  \n","  index_flat = faiss.IndexFlatL2(train_vectors.shape[1])\n","  gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n","  gpu_index_flat.add(augmented_vectors)         # add vectors to the index\n","  D, I = gpu_index_flat.search(train_vectors, k)\n","  print(\"Number of neibs : {}\".format(I.shape[0]*I.shape[1])) \n","  return D,I"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoGio_DmFqNh","colab_type":"code","colab":{}},"source":["def filter_samples_by_dist(distances, indices, augs):\n","  mask_for_ind = np.where(distances < 0.9, 1, -1)\n","  filtred_ind = np.multiply(indices, mask_for_ind)\n","  print(filtred_ind)\n","  augmented_text = []\n","  augmented_lbl_index = []\n","  for row, lbl  in zip(filtred_ind, train['lbl_index'].tolist()):\n","    for ind in row:\n","      if ind > -1:\n","        augmented_text.append(augs[ind])\n","        augmented_lbl_index.append(lbl)\n","  print('Number of samples after filting by distance : {}'.format(len(augmented_text)))\n","  return augmented_text, augmented_lbl_index"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZVOoStDQcD-","colab_type":"code","colab":{}},"source":["def indxs_to_dataframe(augmented_indexs, sentences):\n","  return pd.DataFrame({\"text\":[sentences[i] for i, j in augmented_indexs], \"lbl_index\":[j for i, j in augmented_indexs]}).drop_duplicates()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUoGgmOZIqce","colab_type":"code","colab":{}},"source":["from torch import nn\n","from tqdm import tqdm\n","def bert_proba(boundary, model, sentences):\n","  batch_size = BATCH_SIZE\n","  device = \"cuda\"\n","  tokenizer_ = transformers.BertTokenizer.from_pretrained(pretrained_weights)\n","\n","  train_input_ids, train_attention_masks, sent_filtred_by_len = prep_data(sentences, tokenizer_, MAX_SEQ_LEN)\n","\n","  train_inputs = torch.tensor(train_input_ids)\n","  train_labels = torch.tensor([0]*len(sent_filtred_by_len))\n","  train_masks = torch.tensor(train_attention_masks)\n","  \n","  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","  print(\"Number of sentence augmentations : {}\".format(len(train_data)))\n","  train_dataloader = DataLoader(train_data, shuffle=False, batch_size=batch_size)\n","\n","  model.eval()\n","  augmentations = []\n","  for batch in tqdm(train_dataloader):\n","      \n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      b_input_ids, b_input_mask, b_labels = batch\n","      with torch.no_grad():        \n","              logits = model(b_input_ids)\n","      probs = nn.Softmax(dim=-1)(logits)\n","\n","      probs = probs.detach().cpu().numpy()\n","      samples = []\n","      for indx, i in enumerate(probs.tolist()):\n","        if any(boundary < y for y in i):\n","          samples.append((indx, i.index(max(i))))\n","      augmentations.append(samples)\n","   \n","  aug_samples_indx = []\n","  for ind, i in enumerate(augmentations):\n","    if ind==0:\n","      aug_samples_indx.extend([(j,k) for j,k in i])\n","    else:\n","      aug_samples_indx.extend([((batch_size*ind)+j, k) for j,k in i])\n","  print()\n","  print('Number of augmented samples by Model: {}'.format(len(aug_samples_indx)))\n","  \n","  return indxs_to_dataframe(aug_samples_indx, sent_filtred_by_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSGAEyBE_opf","colab_type":"code","colab":{}},"source":["all_augment_questions = [i[:-1] for i in open('multi_amazon_questions_cleared.txt').readlines()] + [i[:-1] for i in open('SQuAD.txt').readlines()]\n","train_vectors = USE_Embeder(train['text']).numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dnHqon_PPO7","colab_type":"code","outputId":"de0f8bf9-5040-42b1-fd19-0df57bb73730","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import matplotlib.pyplot as plt\n","import torch\n","tr = train\n","\n","b = 25000\n","k = 2\n","for samples_for_faiss in range(0, len(all_augment_questions), 20000):\n","  print('####### NEW PART Of DATA ###########')\n","  part_of_augments = all_augment_questions[samples_for_faiss:samples_for_faiss + b]\n","  aug_vectors = USE_Embeder(part_of_augments).numpy() \n","  distances, indices = get_k_near_neibs(train_vectors, aug_vectors, k)\n","  samples, labels = filter_samples_by_dist(distances, indices, part_of_augments)\n","  for indx_train_m, (f1, m_to_train) in enumerate(list(zip(f1_scores, models))):\n","    print(\"Index of model to train: {}, Current F1 Score :{}\".format(indx_train_m, f1))\n","    new_saples_from_all_eval_models = []\n","    for ind_eval_m, m_evaluator in enumerate(models):\n","      if indx_train_m != ind_eval_m:\n","        print(\"Eval examples by model #{}\".format(ind_eval_m))\n","        new_saples_from_all_eval_models.append(bert_proba(0.7, m_evaluator, samples))\n","    df_merge = pd.merge(new_saples_from_all_eval_models[0], new_saples_from_all_eval_models[1], on=('text',\"lbl_index\"), how='inner')\n","    print(df_merge.head(), df_merge.shape)\n","    df_merge.lbl_index.value_counts().plot(kind='bar')\n","    plt.show()\n","    acccur, f1_new, model = train_BertEmbdLSTMPooling(pd.concat([tr, df_merge]), test)\n","    print(\"Current F1 Score :{}, NEW F1 score {}\".format(f1, f1_new))\n","    if f1_new > f1 - 0.005:\n","      models[indx_train_m] = model\n","      f1_scores[indx_train_m] = f1_new\n","      tr = pd.concat([tr, df_merge])\n","      print(\"########## MODEL updated with f1 score {}. CURRENT TRAIN LEN {} ###############\".format(f1_new, len(tr)))\n","    torch.cuda.empty_cache() \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["####### NEW PART Of DATA ###########\n","Number of neibs : 8008\n","[[-14172  -1621]\n"," [ -5543 -16945]\n"," [ 14846 -16151]\n"," ...\n"," [-10609 -18049]\n"," [-10298 -23360]\n"," [  -960  -6347]]\n","Number of samples after filting by distance : 815\n","Index of model to train: 0, Current F1 Score :0.5968922018368837\n","Eval examples by model #1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7/7 [00:00<00:00, 41.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 815\n","\n","Number of augmented samples by Model: 758\n","Eval examples by model #2\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 7/7 [00:00<00:00, 41.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 815\n","\n","Number of augmented samples by Model: 767\n","                                                text  lbl_index\n","0  Is there an untimed mode ? Can it be used as a...          1\n","1                                what is damations ?          1\n","2                                  what is spirulina          1\n","3  Do u think this would work well as a tennis ba...          1\n","4                              how is it on carpet ?          4 (422, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 4426\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","  Average training loss: 1.02\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.61000\n","  F1: 0.54316\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66400\n","  F1: 0.58653\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.65800\n","  F1: 0.58476\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58857\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.57985\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66200\n","  F1: 0.58184\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66400\n","  F1: 0.58382\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.664, F1:0.588565732221703\n","Current F1 Score :0.5968922018368837, NEW F1 score 0.588565732221703\n","Index of model to train: 1, Current F1 Score :0.594307797362162\n","Eval examples by model #0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7/7 [00:00<00:00, 43.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 815\n","\n","Number of augmented samples by Model: 748\n","Eval examples by model #2\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 7/7 [00:00<00:00, 44.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 815\n","\n","Number of augmented samples by Model: 767\n","                                                text  lbl_index\n","0  Is there an untimed mode ? Can it be used as a...          1\n","1                                what is damations ?          1\n","2  Do u think this would work well as a tennis ba...          1\n","3                              how is it on carpet ?          4\n","4  Can you use these tiles on carpet without dama...          1 (430, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 4434\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","  Average training loss: 1.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.63400\n","  F1: 0.56240\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.20\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.65400\n","  F1: 0.56408\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66400\n","  F1: 0.58353\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.57968\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58776\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.58139\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58792\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.666, F1:0.5879213031695321\n","Current F1 Score :0.594307797362162, NEW F1 score 0.5879213031695321\n","Index of model to train: 2, Current F1 Score :0.5944809093415796\n","Eval examples by model #0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7/7 [00:00<00:00, 43.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 815\n","\n","Number of augmented samples by Model: 748\n","Eval examples by model #1\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 7/7 [00:00<00:00, 45.46it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 815\n","\n","Number of augmented samples by Model: 758\n","                                                text  lbl_index\n","0  Is there an untimed mode ? Can it be used as a...          1\n","1                                what is damations ?          1\n","2  Do u think this would work well as a tennis ba...          1\n","3                              how is it on carpet ?          4\n","4  Can you use these tiles on carpet without dama...          1 (420, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 4424\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","  Average training loss: 1.02\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.58400\n","  F1: 0.52740\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.23\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66800\n","  F1: 0.59502\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67200\n","  F1: 0.59525\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67200\n","  F1: 0.59421\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66400\n","  F1: 0.58520\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58691\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66400\n","  F1: 0.58551\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.664, F1:0.5952463083676865\n","Current F1 Score :0.5944809093415796, NEW F1 score 0.5952463083676865\n","########## MODEL updated with f1 score 0.5952463083676865. CURRENT TRAIN LEN 4424 ###############\n","####### NEW PART Of DATA ###########\n","Number of neibs : 8008\n","[[-13214  -1070]\n"," [ -6653 -11037]\n"," [ 16492 -17878]\n"," ...\n"," [ -3929  -5317]\n"," [ 10218  -8664]\n"," [-12772 -12319]]\n","Number of samples after filting by distance : 775\n","Index of model to train: 0, Current F1 Score :0.5968922018368837\n","Eval examples by model #1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7/7 [00:00<00:00, 41.27it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 775\n","\n","Number of augmented samples by Model: 711\n","Eval examples by model #2\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 7/7 [00:00<00:00, 40.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 775\n","\n","Number of augmented samples by Model: 733\n","                                  text  lbl_index\n","0                 what is \" Stelvio \"?          1\n","1           what is obagi action for ?          1\n","2              What are the deminsions          1\n","3  can i put it on top of the carpet ?          1\n","4               does it work on carpet          1 (398, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 4822\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","  Average training loss: 0.95\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.61400\n","  F1: 0.55006\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.65600\n","  F1: 0.58618\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67400\n","  F1: 0.59530\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67400\n","  F1: 0.59261\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66400\n","  F1: 0.58204\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66200\n","  F1: 0.58028\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66200\n","  F1: 0.58045\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.662, F1:0.5952984719989677\n","Current F1 Score :0.5968922018368837, NEW F1 score 0.5952984719989677\n","########## MODEL updated with f1 score 0.5952984719989677. CURRENT TRAIN LEN 4822 ###############\n","Index of model to train: 1, Current F1 Score :0.594307797362162\n","Eval examples by model #0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7/7 [00:00<00:00, 46.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 775\n","\n","Number of augmented samples by Model: 755\n","Eval examples by model #2\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 7/7 [00:00<00:00, 45.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 775\n","\n","Number of augmented samples by Model: 733\n","                                                text  lbl_index\n","0           what are the dimension of the calculator          4\n","1                               what is \" Stelvio \"?          1\n","2                         what is obagi action for ?          1\n","3                            What are the deminsions          1\n","4  are these really a healthier alternative to sm...          1 (436, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD1CAYAAACrz7WZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAL8UlEQVR4nO3df6zd9V3H8ecLOhcdZoP02hB+7C6m0dSoHV4ZxsWwEBk/jGWJEvhjNAStf0DEaEyq/oH/kPQfXVyixOpwxSgTpwQU4iR1uhjDRkHC+CFZnUXalLZzy9hk2VJ4+8f91h7KLbf3nnvv9+7d5yO5Od/z+X7PPW++3D45/fackqpCktTLOWMPIElaecZdkhoy7pLUkHGXpIaMuyQ1ZNwlqaENYw8AsHHjxpqdnR17DEn6rvLkk09+papmFtq3LuI+OzvLvn37xh5Dkr6rJHnpdPu8LCNJDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqaF18SGmlTC785GxR+DAruvHHkGSAF+5S1JLxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNLRr3JJck+WyS55M8l+TOYf2CJI8l+dJwe/6wniQfT7I/yTNJLlvtfwhJ0pudySv348BvVNUW4Arg9iRbgJ3A3qraDOwd7gNcC2wevnYA96z41JKkt7Vo3KvqcFU9NWx/A3gBuAjYBuwZDtsD3DBsbwPuq3mPA+9JcuGKTy5JOq0lXXNPMgu8H/g8sKmqDg+7XgE2DdsXAS9PPOzgsCZJWiNnHPck5wF/A/xaVb06ua+qCqilPHGSHUn2Jdl37NixpTxUkrSIM4p7kncwH/a/qKq/HZaPnLjcMtweHdYPAZdMPPziYe1Nqmp3Vc1V1dzMzMxy55ckLeBM3i0T4BPAC1X1+xO7Hga2D9vbgYcm1m8Z3jVzBfD1ics3kqQ1sOEMjvlp4KPAF5M8Paz9NrALeCDJbcBLwI3DvkeB64D9wGvArSs6sSRpUYvGvar+Fchpdl+1wPEF3D7lXJKkKfgJVUlqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNbRh7AG08mZ3PjL2CBzYdf3YI0hnNV+5S1JDxl2SGjLuktSQcZekhoy7JDW0aNyT3JvkaJJnJ9Z+N8mhJE8PX9dN7PutJPuTvJjkw6s1uCTp9M7klfsngWsWWP9YVW0dvh4FSLIFuAn4keExf5Tk3JUaVpJ0ZhaNe1V9DvjqGX6/bcCnqurbVfVfwH7g8inmkyQtwzTX3O9I8sxw2eb8Ye0i4OWJYw4Oa5KkNbTcuN8D/CCwFTgM/N5Sv0GSHUn2Jdl37NixZY4hSVrIsuJeVUeq6vWqegP4E05eejkEXDJx6MXD2kLfY3dVzVXV3MzMzHLGkCSdxrLinuTCibsfAU68k+Zh4KYk70zyPmAz8IXpRpQkLdWif3FYkvuBK4GNSQ4CdwFXJtkKFHAA+BWAqnouyQPA88Bx4Paqen11Rpcknc6ica+qmxdY/sTbHH83cPc0Q0mSpuMnVCWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ4vGPcm9SY4meXZi7YIkjyX50nB7/rCeJB9Psj/JM0kuW83hJUkLO5NX7p8ErjllbSewt6o2A3uH+wDXApuHrx3APSszpiRpKRaNe1V9DvjqKcvbgD3D9h7ghon1+2re48B7kly4UsNKks7Mcq+5b6qqw8P2K8CmYfsi4OWJ4w4Oa5KkNTT1H6hWVQG11Mcl2ZFkX5J9x44dm3YMSdKE5cb9yInLLcPt0WH9EHDJxHEXD2tvUVW7q2ququZmZmaWOYYkaSHLjfvDwPZhezvw0MT6LcO7Zq4Avj5x+UaStEY2LHZAkvuBK4GNSQ4CdwG7gAeS3Aa8BNw4HP4ocB2wH3gNuHUVZpYkLWLRuFfVzafZddUCxxZw+7RDSZKm4ydUJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDG6Z5cJIDwDeA14HjVTWX5ALgr4BZ4ABwY1V9bboxJUlLsRKv3D9UVVuram64vxPYW1Wbgb3DfUnSGlqNyzLbgD3D9h7ghlV4DknS25g27gX8Y5Ink+wY1jZV1eFh+xVg05TPIUlaoqmuuQMfrKpDSX4AeCzJf0zurKpKUgs9cPiPwQ6ASy+9dMoxJEmTpnrlXlWHhtujwIPA5cCRJBcCDLdHT/PY3VU1V1VzMzMz04whSTrFsuOe5F1Jvv/ENnA18CzwMLB9OGw78NC0Q0qSlmaayzKbgAeTnPg+f1lV/5DkCeCBJLcBLwE3Tj+mJGkplh33qvoy8OMLrP8PcNU0Q0mSpuMnVCWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1NC0f/2AtK7N7nxk7BE4sOv6sUfQWchX7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1tGHsASStjdmdj4w9Agd2XT/2CGcNX7lLUkOrFvck1yR5Mcn+JDtX63kkSW+1KnFPci7wh8C1wBbg5iRbVuO5JElvtVqv3C8H9lfVl6vqO8CngG2r9FySpFOkqlb+mya/AFxTVb803P8o8IGqumPimB3AjuHuDwEvrvggS7cR+MrYQ6wTnouTPBcneS5OWg/n4r1VNbPQjtHeLVNVu4HdYz3/QpLsq6q5sedYDzwXJ3kuTvJcnLTez8VqXZY5BFwycf/iYU2StAZWK+5PAJuTvC/J9wA3AQ+v0nNJkk6xKpdlqup4kjuAzwDnAvdW1XOr8VwrbF1dJhqZ5+Ikz8VJnouT1vW5WJU/UJUkjctPqEpSQ8Zdkhoy7pLUkHHXWyS5b+wZ1oMkH0zy60muHnuWMSS5PMlPDttbhnNx3dhzjSHJDye5Ksl5p6xfM9ZMi/EPVBeQ5Naq+rOx51gLSU59i2qADwH/BFBVP7/mQ40kyReq6vJh+5eB24EHgauBv6uqXWPOt5aS3MX83w21AXgM+ADwWeBngc9U1d0jjremkvwq8z8LLwBbgTur6qFh31NVddmY852OcV9Akv+uqkvHnmMtJHkKeB74U6CYj/v9zH82gar6l/GmW1tJ/r2q3j9sPwFcV1XHkrwLeLyqfnTcCddOki8yH7J3Aq8AF1fVq0m+F/h8Vf3YqAOuoeFc/FRVfTPJLPBp4M+r6g8mf2bWm7P2f9aR5JnT7QI2reUsI5sD7gR+B/jNqno6ybfOpqhPOCfJ+cxfrkxVHQOoqv9Ncnzc0dbc8ap6HXgtyX9W1asAVfWtJG+MPNtaO6eqvglQVQeSXAl8Osl7me/FunTWxp35gH8Y+Nop6wH+be3HGUdVvQF8LMlfD7dHOHt/Lt4NPMn8z0AlubCqDg/XWdftL+JV8p0k31dVrwE/cWIxybuBsy3uR5JsraqnAYZX8D8H3Aus29/Nna2/iAH+HjjvxL+wSUn+ee3HGVdVHQR+Mcn1wKtjzzOGqpo9za43gI+s4Sjrwc9U1bfh/18AnPAOYPs4I43mFuBNv3OrquPALUn+eJyRFuc1d0lqyLdCSlJDxl2SGjLuktSQcZekhoy7JDX0f5iIvNGAptEtAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 5258\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","  Average training loss: 0.89\n","  Training epcoh took: 0:00:04\n","\n","Running Validation...\n","  Accuracy: 0.62600\n","  F1: 0.56240\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.65600\n","  F1: 0.58586\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.02\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.58147\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58913\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.58242\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66200\n","  F1: 0.58303\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66000\n","  F1: 0.58226\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.66, F1:0.5891302567029003\n","Current F1 Score :0.594307797362162, NEW F1 score 0.5891302567029003\n","Index of model to train: 2, Current F1 Score :0.5952463083676865\n","Eval examples by model #0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7/7 [00:00<00:00, 45.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 775\n","\n","Number of augmented samples by Model: 755\n","Eval examples by model #1\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 7/7 [00:00<00:00, 45.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Number of sentence augmentations : 775\n","\n","Number of augmented samples by Model: 711\n","                                  text  lbl_index\n","0                 what is \" Stelvio \"?          1\n","1           what is obagi action for ?          1\n","2              What are the deminsions          1\n","3  can i put it on top of the carpet ?          1\n","4               does it work on carpet          1 (412, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Not used sentence because it bpe len > 64 : 0\n","Not used sentence because it bpe len > 64 : 0\n","Training example : 5234\n","Valid example : 500\n","\n","======== Epoch 1 / 7 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","  Average training loss: 0.91\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.64000\n","  F1: 0.56620\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.62600\n","  F1: 0.54980\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","\n","  Average training loss: 0.02\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.66600\n","  F1: 0.58545\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67600\n","  F1: 0.59467\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67600\n","  F1: 0.59494\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67600\n","  F1: 0.59494\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","\n","  Average training loss: 0.00\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.67400\n","  F1: 0.59310\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Accuracy: 0.674, F1:0.5949402914310266\n","Current F1 Score :0.5952463083676865, NEW F1 score 0.5949402914310266\n","########## MODEL updated with f1 score 0.5949402914310266. CURRENT TRAIN LEN 5234 ###############\n","####### NEW PART Of DATA ###########\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4AjkEHXPuzE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}